# Lezer-style Incremental Repair Implementation

## Summary

This document describes the Lezer-style incremental repair features that have been added to the parser. The implementation builds on the existing Wagner-Graham algorithm infrastructure and adds key Lezer concepts for efficient incremental parsing.

## What Was Implemented

### 1. Selective Cache Invalidation

**Files Modified:**
- [token_cache.mbt:110-134](token_cache.mbt#L110-L134)
- [parse_cache.mbt:112-137](parse_cache.mbt#L112-L137)

**What Changed:**
- **Before:** Version-based invalidation that invalidated ALL cache entries on every edit
- **After:** Range-based selective invalidation that only invalidates entries overlapping the damaged range

**Lezer Concept:** This implements Lezer's principle of preserving valid cached data outside the damaged region for reuse.

**Code Example:**
```moonbit
// Only invalidate cache entries that overlap with the damaged range
self.cache.iter().each(fn(entry) {
  let (key, cached) = entry
  let node = cached.node
  // Check if the cached node overlaps with the damaged range
  if node.start < range.end && node.end > range.start {
    keys_to_remove.push(key)
  }
})
```

**Benefits:**
- Preserves valid cache entries outside damaged regions
- Reduces re-tokenization and re-parsing overhead
- Enables efficient incremental updates for localized edits

### 2. Incremental Reparse Infrastructure

**File Modified:**
- [incremental_parser.mbt:74-109](incremental_parser.mbt#L74-L109)

**What Changed:**
- Replaced direct `parse_with_error_recovery` call with `incremental_reparse` function
- Added framework for tree fragment reuse (currently falls back to full reparse)
- Documented the path forward for child-level reuse

**Current Behavior:**
The implementation currently performs full reparsing, but the infrastructure is in place for:
1. Identifying damaged vs undamaged regions
2. Selectively invalidating only damaged cache entries
3. Position adjustment of old tree nodes
4. Tree reconstruction from reused + reparsed fragments

**Future Enhancement (TODO at line 98):**
```moonbit
// TODO: Implement child-level tree fragment reuse:
// 1. Walk through adjusted_tree children
// 2. Identify children completely outside damaged_range
// 3. Reuse those children directly (Lezer-style fragment reuse)
// 4. Only reparse children that overlap damaged_range
// 5. Reconstruct the tree from reused + reparsed children
```

### 3. Comprehensive Test Coverage

**File Modified:**
- [incremental_parser_test.mbt:122-220](incremental_parser_test.mbt#L122-L220)

**New Tests Added:**
1. **Selective cache invalidation - token cache** (line 124)
2. **Selective cache invalidation - parse cache** (line 137)
3. **Tree fragment reuse for unchanged regions** (line 150)
4. **Minimal reparsing for local edits** (line 169)
5. **Multiple incremental edits preserve correctness** (line 183)
6. **Damage tracking accuracy** (line 208)

**Test Results:**
- âœ… All 131 tests passing
- âœ… All 36 benchmarks passing

## Architecture

### Lezer-Style Components Now Present

| Component | Status | Implementation |
|-----------|--------|----------------|
| **Tree Fragment Caching** | ðŸŸ¡ Partial | Cache infrastructure ready, reuse logic pending |
| **Selective Invalidation** | âœ… Complete | Range-based overlap detection |
| **Damage Tracking** | âœ… Complete | Wagner-Graham algorithm with position adjustment |
| **Position Adjustment** | âœ… Complete | Shifts nodes based on edit delta |
| **Error Recovery** | âœ… Complete | Panic mode with synchronization points |
| **Cache Management** | âœ… Complete | Token cache + Parse cache with LRU eviction |

### Data Flow

```
Edit Applied
    â†“
Update Source Text
    â†“
Adjust Old Tree Positions (Wagner-Graham)
    â†“
Identify Damaged Range (DamageTracker)
    â†“
Selective Cache Invalidation â† LEZER-STYLE
  - Token Cache: Remove overlapping entries
  - Parse Cache: Remove overlapping entries
    â†“
Incremental Reparse
  - Currently: Full reparse
  - TODO: Selective reparse with fragment reuse â† LEZER-STYLE
    â†“
Return New Tree
```

## Performance Characteristics

### Benchmark Results

**Incremental Edits:**
- Small edit: ~0.61 Âµs (typing simulation)
- Edit at start: ~4.68 Âµs
- Edit at end: ~4.70 Âµs
- Edit in middle: ~4.78 Âµs

**Cache Effectiveness:**
- Repeated parsing: ~1.66 Âµs
- Similar expressions: ~0.62 Âµs
- Parse cache get: ~0.17 Âµs

**Damage Tracking:**
- Localized damage: ~0.30 Âµs
- Widespread damage: ~1.65 Âµs
- Position adjustment: ~0.80 Âµs

**Full Parsing (for comparison):**
- Simple: ~0.09 Âµs
- Lambda: ~0.25 Âµs
- Complex: ~1.21 Âµs

## Benefits Achieved

### 1. Memory Efficiency
- Selective invalidation preserves valid cache entries
- Reduces memory churn from full cache invalidation
- LRU eviction prevents unbounded cache growth

### 2. Correctness
- All 131 tests passing demonstrates correctness
- Incremental results match full reparse results
- Error recovery works correctly with incremental updates

### 3. Foundation for Future Optimization
The infrastructure is now in place for full Lezer-style tree fragment reuse:
- Damage tracking identifies minimal damaged region
- Cache entries outside damaged region are preserved
- Position adjustment prepares old tree for splicing
- Only need to implement the tree reconstruction logic

## Comparison: Before vs After

### Before (Version-Based Invalidation)

```moonbit
pub fn TokenCache::invalidate_range(self, _start, _end) -> Unit {
  // Invalidates ALL entries
  self.version = self.version + 1
}
```

**Problem:** Every edit invalidated the entire cache, forcing re-tokenization and re-parsing of unchanged code.

### After (Selective Invalidation)

```moonbit
pub fn TokenCache::invalidate_range(self, start, end) -> Unit {
  self.version = self.version + 1

  // Only invalidate overlapping entries
  let keys_to_remove = []
  self.cache.iter().each(fn(entry) {
    let (key, _) = entry
    if key.start < end && key.end > start {
      keys_to_remove.push(key)
    }
  })

  for key in keys_to_remove {
    self.cache.remove(key)
  }
}
```

**Benefit:** Preserves valid cache entries outside the edit region, enabling efficient incremental updates.

## Next Steps for Full Lezer-Style Incremental Repair

To achieve complete Lezer-style incremental repair, implement the TODO at [incremental_parser.mbt:98-105](incremental_parser.mbt#L98-L105):

1. **Walk the adjusted tree** and identify children outside the damaged range
2. **Reuse those children directly** without reparsing
3. **Only reparse children** that overlap the damaged range
4. **Reconstruct the tree** by splicing reused and newly parsed nodes
5. **Maintain node identity** to support advanced editor features

This would provide the full benefit of Lezer-style incremental parsing where only the damaged portions of the document are reparsed, with the rest reused from the previous parse.

## References

- [Lezer Documentation](https://lezer.codemirror.net/)
- [Lezer Announcement Blog](https://marijnhaverbeke.nl/blog/lezer.html)
- [Wagner-Graham Paper (1998)](https://dl.acm.org/doi/10.1145/293677.293678) - "Efficient and Flexible Incremental Parsing"
- [lezer.md](lezer.md) - Detailed explanation of Lezer concepts

## Conclusion

The parser now includes key Lezer-style incremental repair features:
- âœ… Selective cache invalidation (range-based overlap detection)
- âœ… Infrastructure for tree fragment reuse
- âœ… Comprehensive test coverage
- ðŸŸ¡ Ready for final optimization: child-level fragment reuse

The implementation provides a solid foundation for efficient incremental parsing while maintaining correctness and compatibility with the existing CRDT integration.
